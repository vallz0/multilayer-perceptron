# Multi-Layer Perceptron from Scratch

A simple Multi-Layer Perceptron (MLP) implemented from scratch in Python without external libraries. This project follows Object-Oriented Programming (OOP) principles and clean code practices with type hints. The neural network supports feedforward, backpropagation, and training using basic datasets.

## Features
- No external dependencies
- Modular and object-oriented design
- Implements forward propagation and backpropagation
- Trains on simple datasets (e.g., AND logic gate)

## File Structure
```
|-- neural_network.py   # Core MLP implementation
|-- main.py             # Example usage and training
|-- README.md           # Project documentation
```

## Installation
No additional libraries are required. Just ensure you have Python installed.

## Usage
1. Clone the repository:
   ```bash
   git clone https://github.com/vallz0/multilayer-perceptron
   cd multilayer-perceptron
   ```
2. Run the training script:
   ```bash
   python main.py
   ```

## Example Output
```
Input: [0, 0], Prediction: [0.05]
Input: [0, 1], Prediction: [0.94]
Input: [1, 0], Prediction: [0.92]
Input: [1, 1], Prediction: [0.08]
```

